{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22942f7e-3446-4009-b551-cca7fcc25d73",
   "metadata": {},
   "source": [
    "# Reflexion\n",
    "\n",
    "[Reflexion](https://arxiv.org/abs/2303.11366) by Shinn, et. al., is an architecture designed to learn through verbal feedback and self-reflection. The agent explicitly critiques its responses for tasks to generate a higher quality final response, at the expense of longer execution time.\n",
    "\n",
    "![reflexion diagram](./imgs/reflexion.png)\n",
    "\n",
    "The paper outlines 3 main components:\n",
    "\n",
    "1. Actor (agent) with self-reflection\n",
    "2. External evaluator (task-specific, e.g. code compilation steps)\n",
    "3. Episodic memory that stores the reflections from (1).\n",
    "\n",
    "In their code, the last two components are very task-specific, so in this notebook, you will build the _actor_ in LangGraph.\n",
    "\n",
    "To skip to the graph definition, see the [Construct Graph section](#Construct-Graph) below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906edf48-7c81-48b8-8250-fdc34043d01b",
   "metadata": {},
   "source": [
    "## 0. Prerequisites\n",
    "\n",
    "Install `langgraph` (for the framework), `langchain_openai` (for the LLM), and `langchain` + `tavily-python` (for the search engine).\n",
    "\n",
    "We will use tavily search as a tool. You can get an API key [here](https://app.tavily.com/sign-in) or replace with a different tool of your choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b64a6f6-1d32-48be-92b5-66c3b04b17f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find an activated virtualenv (required).\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Could not find an activated virtualenv (required).\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U --quiet  langchain langgraph langchain_openai\n",
    "%pip install -U --quiet tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a917bb70-f84c-48e6-8d32-d14f9df2ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str) -> None:\n",
    "    if os.environ.get(var):\n",
    "        return\n",
    "    os.environ[var] = getpass.getpass(var)\n",
    "\n",
    "\n",
    "# Optional: Configure tracing to visualize and debug the agent\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Reflexion\"\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af543598-52d0-4ec3-a05f-d2954ff793ee",
   "metadata": {},
   "source": [
    "## 1. Actor (with reflection)\n",
    "\n",
    "The main component of Reflexion is the \"`actor`\", which is an agent that reflects on its response and re-executes to improve based on self-critique. It's main sub-components include:\n",
    "1. Tools/tool execution\n",
    "2. Initial responder: generate an initial response (and self-reflection)\n",
    "3. Revisor: re-respond (and reflec) based on previous reflections\n",
    "\n",
    "We'll first define the tool execution context.\n",
    "\n",
    "#### Construct tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2ac853-b8a6-40de-b7fe-3f9f3c5ca4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "\n",
    "search = TavilySearchAPIWrapper()\n",
    "tavily_tool = TavilySearchResults(api_wrapper=search, max_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737fd31c-b4e9-47f9-a4e8-99fab340a028",
   "metadata": {},
   "source": [
    "The tools are invoked _in context_. Create a function that invokes all the requested tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f144fc-e6fa-4e4f-a8af-1a0650e79fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import List\n",
    "\n",
    "from langchain.output_parsers.openai_tools import (\n",
    "    JsonOutputToolsParser,\n",
    "    PydanticToolsParser,\n",
    ")\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
    "\n",
    "# This a helper class we have that is useful for running tools\n",
    "# It takes in an agent action and calls that tool and returns the result\n",
    "tool_executor = ToolExecutor([tavily_tool])\n",
    "# Parse the tool messages for the execution / invocation\n",
    "parser = JsonOutputToolsParser(return_id=True)\n",
    "\n",
    "\n",
    "def execute_tools(state: List[BaseMessage]) -> List[BaseMessage]:\n",
    "    tool_invocation: AIMessage = state[-1]\n",
    "    parsed_tool_calls = parser.invoke(tool_invocation)\n",
    "    ids = []\n",
    "    tool_invocations = []\n",
    "    for parsed_call in parsed_tool_calls:\n",
    "        for query in parsed_call[\"args\"][\"search_queries\"]:\n",
    "            tool_invocations.append(\n",
    "                ToolInvocation(\n",
    "                    # We only have this one for now. Would want to map it\n",
    "                    # if we change\n",
    "                    tool=\"tavily_search_results_json\",\n",
    "                    tool_input=query,\n",
    "                )\n",
    "            )\n",
    "            ids.append(parsed_call[\"id\"])\n",
    "\n",
    "    outputs = tool_executor.batch(tool_invocations)\n",
    "    outputs_map = defaultdict(dict)\n",
    "    for id_, output, invocation in zip(ids, outputs, tool_invocations):\n",
    "        outputs_map[id_][invocation.tool_input] = output\n",
    "\n",
    "    return [\n",
    "        ToolMessage(content=json.dumps(query_outputs), tool_call_id=id_)\n",
    "        for id_, query_outputs in outputs_map.items()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093fbaa0-9a71-4c32-9872-02a9aec9b35d",
   "metadata": {},
   "source": [
    "#### Initial responder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fffa8d5-068a-4f0b-adfc-b4daf30ef294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, ValidationError\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith import traceable\n",
    "\n",
    "actor_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are expert researcher.\n",
    "Current time: {time}\n",
    "\n",
    "1. {first_instruction}\n",
    "2. Reflect and critique your answer. Be severe to maximize improvement.\n",
    "3. Recommend search queries to research information and improve your answer.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"system\", \"Answer the user's question above using the required format.\"),\n",
    "    ]\n",
    ").partial(\n",
    "    time=lambda: datetime.datetime.now().isoformat(),\n",
    ")\n",
    "\n",
    "\n",
    "class Reflection(BaseModel):\n",
    "    missing: str = Field(description=\"Critique of what is missing.\")\n",
    "    superfluous: str = Field(description=\"Critique of what is superfluous\")\n",
    "\n",
    "\n",
    "class AnswerQuestion(BaseModel):\n",
    "    \"\"\"Answer the question.\"\"\"\n",
    "\n",
    "    answer: str = Field(description=\"~250 word detailed answer to the question.\")\n",
    "    reflection: Reflection = Field(description=\"Your reflection on the initial answer.\")\n",
    "    search_queries: List[str] = Field(\n",
    "        description=\"1-3 search queries for researching improvements to address the critique of your current answer.\"\n",
    "    )\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "initial_answer_chain = actor_prompt_template.partial(\n",
    "    first_instruction=\"Provide a detailed ~250 word answer.\"\n",
    ") | llm.bind_tools(tools=[AnswerQuestion], tool_choice=\"AnswerQuestion\")\n",
    "validator = PydanticToolsParser(tools=[AnswerQuestion])\n",
    "\n",
    "\n",
    "class ResponderWithRetries:\n",
    "    def __init__(self, runnable, validator):\n",
    "        self.runnable = runnable\n",
    "        self.validator = validator\n",
    "\n",
    "    @traceable\n",
    "    def respond(self, state: List[BaseMessage]):\n",
    "        response = []\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                response = self.runnable.invoke({\"messages\": state})\n",
    "                self.validator.invoke(response)\n",
    "                return response\n",
    "            except ValidationError as e:\n",
    "                state = state + [HumanMessage(content=repr(e))]\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a0264b8-ed2d-4f15-9d3c-085aa3a5edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_responder = ResponderWithRetries(\n",
    "    runnable=initial_answer_chain, validator=validator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5922e1fe-7533-4f41-8b1d-d812707c1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_question = \"Why is reflection useful in AI?\"\n",
    "initial = first_responder.respond([HumanMessage(content=example_question)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74079c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9Tc3bt8wjMz1sCaxh9I10Sk3', 'function': {'arguments': '{\"answer\":\"Reflection in AI, often referred to as self-awareness or meta-reasoning, is crucial for several reasons. Firstly, it allows AI systems to understand and improve their own decision-making processes. By reflecting on their actions and outcomes, AI can identify patterns of success or failure, leading to self-improvement over time. This capability is essential for developing AI that can adapt to new challenges and environments without human intervention.\\\\n\\\\nSecondly, reflection enables AI to explain its decisions and actions to humans. This is particularly important in areas where transparency and trust are critical, such as healthcare, finance, and autonomous vehicles. An AI that can introspect and communicate the reasoning behind its decisions is more likely to be trusted by users and can help in demystifying AI operations.\\\\n\\\\nLastly, reflection is key to achieving higher levels of cognitive abilities in AI, such as creativity, strategic thinking, and problem-solving. By analyzing its own thought processes, an AI can explore alternative strategies, learn from past experiences, and innovate. This capacity for self-improvement and adaptability is what distinguishes advanced AI systems from basic automation tools.\\\\n\\\\nIn summary, reflection is an indispensable tool in AI development, enabling self-improvement, transparency, and higher cognitive functions. It\\'s what allows AI to not just perform tasks but to grow and evolve in complexity and usefulness.\",\"reflection\":{\"missing\":\"I did not include specific examples of AI systems that utilize reflection or discuss the technical mechanisms by which AI can achieve reflection.\",\"superfluous\":\"The answer could have been more concise in explaining the importance of reflection in AI without delving into the broader implications for different sectors like healthcare and finance. This detail, while informative, may not be directly necessary for understanding the core concept of reflection in AI.\"},\"search_queries\":[\"AI reflection mechanisms\",\"Examples of reflective AI systems\",\"Technical overview of AI self-improvement\"]}', 'name': 'AnswerQuestion'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 383, 'prompt_tokens': 226, 'total_tokens': 609}, 'model_name': 'gpt-4-turbo-preview', 'system_fingerprint': 'fp_122114e45f', 'finish_reason': 'stop', 'logprobs': None}, id='run-774577e7-9851-413c-9fe6-2693ce9af52c-0', tool_calls=[{'name': 'AnswerQuestion', 'args': {'answer': \"Reflection in AI, often referred to as self-awareness or meta-reasoning, is crucial for several reasons. Firstly, it allows AI systems to understand and improve their own decision-making processes. By reflecting on their actions and outcomes, AI can identify patterns of success or failure, leading to self-improvement over time. This capability is essential for developing AI that can adapt to new challenges and environments without human intervention.\\n\\nSecondly, reflection enables AI to explain its decisions and actions to humans. This is particularly important in areas where transparency and trust are critical, such as healthcare, finance, and autonomous vehicles. An AI that can introspect and communicate the reasoning behind its decisions is more likely to be trusted by users and can help in demystifying AI operations.\\n\\nLastly, reflection is key to achieving higher levels of cognitive abilities in AI, such as creativity, strategic thinking, and problem-solving. By analyzing its own thought processes, an AI can explore alternative strategies, learn from past experiences, and innovate. This capacity for self-improvement and adaptability is what distinguishes advanced AI systems from basic automation tools.\\n\\nIn summary, reflection is an indispensable tool in AI development, enabling self-improvement, transparency, and higher cognitive functions. It's what allows AI to not just perform tasks but to grow and evolve in complexity and usefulness.\", 'reflection': {'missing': 'I did not include specific examples of AI systems that utilize reflection or discuss the technical mechanisms by which AI can achieve reflection.', 'superfluous': 'The answer could have been more concise in explaining the importance of reflection in AI without delving into the broader implications for different sectors like healthcare and finance. This detail, while informative, may not be directly necessary for understanding the core concept of reflection in AI.'}, 'search_queries': ['AI reflection mechanisms', 'Examples of reflective AI systems', 'Technical overview of AI self-improvement']}, 'id': 'call_9Tc3bt8wjMz1sCaxh9I10Sk3'}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dde8997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['args', 'id', 'type'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parsed[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "782e9630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['answer', 'reflection', 'search_queries'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed[0]['args'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20901d77-0f5f-4596-90a4-412c0ac5f2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': {'answer': \"Reflection in AI refers to the ability of an AI system to analyze and improve its own processes, decisions, and outcomes. This metacognitive capability enhances the AI's adaptability, efficiency, and reliability, making it crucial for creating more sophisticated and autonomous systems. Reflective AI models can identify weaknesses or biases in their decision-making processes, learn from past actions, and adjust their strategies accordingly. This self-improvement loop enables AI to adapt to new or changing environments without requiring constant human intervention, making it particularly valuable in dynamic or complex domains such as autonomous vehicles, healthcare diagnosis, and financial market analysis.\\n\\nMoreover, reflective AI plays a significant role in explicability and trustworthiness. By understanding and explaining its decision-making process, AI can provide insights into its behavior, fostering trust and acceptance among users. This is particularly important in sectors where decisions have significant consequences, such as healthcare and criminal justice. In summary, reflection allows AI to become more self-sufficient, adaptable, and transparent, which are key qualities for advanced AI systems operating in diverse and unpredictable environments.\",\n",
       "   'reflection': {'missing': 'The answer could benefit from specific examples or case studies that illustrate the importance of reflection in AI. Additionally, it could mention the technical challenges and current limitations in implementing reflective AI systems.',\n",
       "    'superfluous': 'The answer might be a bit repetitive in emphasizing the benefits of reflective AI across different domains. It could streamline the explanation for brevity and focus more on the mechanics of how reflection is implemented in AI systems.'},\n",
       "   'search_queries': ['case studies on reflective AI',\n",
       "    'technical challenges in implementing reflective AI',\n",
       "    'how is reflection implemented in AI systems']},\n",
       "  'id': 'call_fqV9DjaKLM3vKvCICRH3FZeI',\n",
       "  'type': 'AnswerQuestion'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = parser.invoke(initial)\n",
    "parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c7af31-b469-46fc-b441-0acb28515c7a",
   "metadata": {},
   "source": [
    "#### Revision\n",
    "\n",
    "The second part of the actor is a revision step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605fd8d-c663-446f-ba25-751190195749",
   "metadata": {},
   "outputs": [],
   "source": [
    "revise_instructions = \"\"\"Revise your previous answer using the new information.\n",
    "    - You should use the previous critique to add important information to your answer.\n",
    "        - You MUST include numerical citations in your revised answer to ensure it can be verified.\n",
    "        - Add a \"References\" section to the bottom of your answer (which does not count towards the word limit). In form of:\n",
    "            - [1] https://example.com\n",
    "            - [2] https://example.com\n",
    "    - You should use the previous critique to remove superfluous information from your answer and make SURE it is not more than 250 words.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Extend the initial answer schema to include references.\n",
    "# Forcing citation in the model encourages grounded responses\n",
    "class ReviseAnswer(AnswerQuestion):\n",
    "    \"\"\"Revise your original answer to your question.\"\"\"\n",
    "\n",
    "    references: List[str] = Field(\n",
    "        description=\"Citations motivating your updated answer.\"\n",
    "    )\n",
    "\n",
    "\n",
    "revision_chain = actor_prompt_template.partial(\n",
    "    first_instruction=revise_instructions\n",
    ") | llm.bind_tools(tools=[ReviseAnswer], tool_choice=\"ReviseAnswer\")\n",
    "revision_validator = PydanticToolsParser(tools=[ReviseAnswer])\n",
    "\n",
    "revisor = ResponderWithRetries(runnable=revision_chain, validator=revision_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd51f17-c0b0-44b6-90e2-55a66cb8f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "revised = revisor.respond(\n",
    "    [\n",
    "        HumanMessage(content=\"\"),\n",
    "        initial,\n",
    "        ToolMessage(\n",
    "            tool_call_id=initial.additional_kwargs[\"tool_calls\"][0][\"id\"],\n",
    "            content=json.dumps(\n",
    "                tavily_tool.invoke(str(parsed[0][\"args\"][\"search_queries\"]))\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28685e81-5461-47fe-bebd-2af6e552761b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': {'answer': 'Reflection in AI involves systems analyzing, understanding, and learning from their actions to improve continuously. This capability is essential for intelligent systems operating in dynamic environments, allowing them to evaluate performance, identify inefficiencies, and adjust strategies autonomously, thereby enhancing autonomy and adaptability [1]. Reflective AI plays a significant role in developing explainable AI (XAI), facilitating systems to provide insights into their decision-making processes, thus improving transparency and trust [2]. Moreover, it aids in identifying and rectifying ethical and bias-related issues, ensuring fairness and accountability in AI operations [3]. However, implementing reflective AI presents challenges, including the complexity of AI systems, the interdisciplinary divide between ethics and engineering, and the lack of established methods for ethical AI engineering [4]. These challenges highlight the necessity for continuous ethical reflection and collaborative exchange within development teams to bridge the gap between theoretical ethics and practical AI applications [5].\\n\\nReferences:\\n[1] https://link.springer.com/article/10.1007/s11948-023-00443-3\\n[2] https://dl.acm.org/doi/10.1145/3599974\\n[3] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8455229/\\n[4] https://link.springer.com/article/10.1007/s11948-023-00443-3\\n[5] https://link.springer.com/article/10.1007/s11948-023-00443-3',\n",
       "   'reflection': {'missing': 'The initial answer lacked concrete examples and did not address the challenges associated with implementing reflection in AI.',\n",
       "    'superfluous': 'Excessive detailing on the benefits of reflection in AI could have been condensed to accommodate a balanced discussion on challenges and practical applications.'},\n",
       "   'search_queries': ['current examples of reflective AI',\n",
       "    'implementation challenges of reflective AI',\n",
       "    'case studies on ethical reflection in AI'],\n",
       "   'references': ['https://link.springer.com/article/10.1007/s11948-023-00443-3',\n",
       "    'https://dl.acm.org/doi/10.1145/3599974',\n",
       "    'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8455229/']},\n",
       "  'id': 'call_oGxm9DIcOoY5VmZ5gwFTcMIg',\n",
       "  'type': 'ReviseAnswer'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = parser.invoke(revised)\n",
    "parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623a6c9-b69b-438c-9e6e-34a8883e0623",
   "metadata": {},
   "source": [
    "## Construct Graph\n",
    "\n",
    "\n",
    "Now we can wire all our components together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c57318f-a30c-4dbd-9b88-f2633e8cb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, MessageGraph\n",
    "\n",
    "MAX_ITERATIONS = 5\n",
    "builder = MessageGraph()\n",
    "builder.add_node(\"draft\", first_responder.respond)\n",
    "builder.add_node(\"execute_tools\", execute_tools)\n",
    "builder.add_node(\"revise\", revisor.respond)\n",
    "# draft -> execute_tools\n",
    "builder.add_edge(\"draft\", \"execute_tools\")\n",
    "# execute_tools -> revise\n",
    "builder.add_edge(\"execute_tools\", \"revise\")\n",
    "\n",
    "# Define looping logic:\n",
    "\n",
    "\n",
    "def _get_num_iterations(state: List[BaseMessage]):\n",
    "    i = 0\n",
    "    for m in state[::-1]:\n",
    "        if not isinstance(m, (ToolMessage, AIMessage)):\n",
    "            break\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "def event_loop(state: List[BaseMessage]) -> str:\n",
    "    # in our case, we'll just stop after N plans\n",
    "    num_iterations = _get_num_iterations(state)\n",
    "    if num_iterations > MAX_ITERATIONS:\n",
    "        return END\n",
    "    return \"execute_tools\"\n",
    "\n",
    "\n",
    "# revise -> execute_tools OR end\n",
    "builder.add_conditional_edges(\"revise\", event_loop)\n",
    "builder.set_entry_point(\"draft\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634a3ea-7423-4579-9f4e-390e439c3209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 1. draft\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_vXIkxGNqzzqsmkmVUvpY81Wx', 'function': {'a ...\n",
      "---\n",
      "## 2. execute_tools\n",
      "[ToolMessage(content='{\"examples of successful climate policies\": [{\"url\": \"https://www.washingtonpo ...\n",
      "---\n",
      "## 3. revise\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_PQqwbqcN9a2pVpf11sTTMAB4', 'function': {'a ...\n",
      "---\n",
      "## 4. execute_tools\n",
      "[ToolMessage(content='{\"successful climate change mitigation projects\": [{\"url\": \"https://unfccc.int ...\n",
      "---\n",
      "## 5. revise\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_v0NA4y1gJgg4fRiwU0cgGMaS', 'function': {'a ...\n",
      "---\n",
      "## 6. execute_tools\n",
      "[ToolMessage(content='{\"successful climate change mitigation projects\": [{\"url\": \"https://unfccc.int ...\n",
      "---\n",
      "## 7. revise\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_8o5fOQHDTArbp5yPk3ffsLTZ', 'function': {'a ...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    [HumanMessage(content=\"How should we handle the climate crisis?\")]\n",
    ")\n",
    "for i, step in enumerate(events):\n",
    "    node, output = next(iter(step.items()))\n",
    "    print(f\"## {i+1}. {node}\")\n",
    "    print(str(output)[:100] + \" ...\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e698a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstep\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'step' is not defined"
     ]
    }
   ],
   "source": [
    "step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9451410a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer\n",
      "To effectively address the climate crisis, a multifaceted strategy involving international cooperation, strong national policies, technological innovations, education, and ecosystem protection is crucial. International cooperation, exemplified by the Paris Agreement, is essential for setting and achieving global emissions reduction targets. Sharing technologies and strategies across nations can significantly mitigate climate change impacts [1]. On a national level, innovative policies like Finland's pioneering carbon tax demonstrate the potential of national initiatives to combat climate change [2]. Technological advancements also play a critical role, with investments in renewable energy and energy efficiency initiatives leading to significant climate policy successes [3]. Education is a powerful tool that empowers individuals with the knowledge and skills necessary for climate action, highlighting its importance in the global fight against climate change [4]. Moreover, protecting and restoring ecosystems are vital for climate change mitigation, as they significantly contribute to carbon capture and storage, showcasing the critical role of nature in addressing the climate crisis [5]. Implementing a combination of these strategies can mitigate the worst impacts of the climate crisis and pave the way for a sustainable future.\n",
      "----\n",
      "reflection\n",
      "{'missing': 'The original response lacked specific examples of successful policies, detailed information on the role of education, and a discussion on the importance of ecosystems in mitigating climate change.', 'superfluous': 'The initial response was too generic, lacking specific examples and evidence to support the proposed solutions.'}\n",
      "----\n",
      "search_queries\n",
      "['successful climate change mitigation projects', 'education programs for climate action', 'role of ecosystems in reducing carbon emissions']\n",
      "----\n",
      "references\n",
      "['[1] https://www.washingtonpost.com/climate-solutions/2022/04/21/climate-change-policy-examples-list/', '[2] https://www.usnews.com/news/best-countries/slideshows/these-countries-are-leading-the-way-in-climate-policy', '[3] https://www.worldbank.org/en/news/feature/2023/09/19/climate-policies-with-real-world-results', '[4] https://www.unesco.org/en/articles/how-can-education-strengthen-climate-action', '[5] https://climatepromise.undp.org/news-and-stories/what-climate-change-mitigation-and-why-it-urgent']\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for args_label in parser.invoke(step['revise'])[0][\"args\"]:\n",
    "    \n",
    "    parser.invoke(step['revise'])[0][\"args\"][args_label]\n",
    "    \n",
    "    print(args_label)\n",
    "    print()\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9195436-aed9-4356-948b-2ca081a6d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(parser.invoke(step[END][-1])[0][\"args\"][\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7159e30c-728e-480d-8252-915404cc756d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congrats on building a Reflexion actor! I'll leave you with a few observations to save you some time when choosing which parts of this agent ot adapt to your workflow:\n",
    "1. This agent trades off execution time for quality. It explicitly forces the agent to critique and revise the output over several steps, which usually (not always) increases the response quality but takes much longer to return a final answer\n",
    "2. The 'reflections' can be paired with additional external feedback (such as validators), to further guide the actor.\n",
    "3. In the paper, 1 environment (AlfWorld) uses external memory. It does this by storing summaries of the reflections to an external store and using them in subsequent trials/invocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c1961-64f6-41f1-9b80-f09deffae21f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
